# LLM Provider Configuration
# Choose one: openai, anthropic, google, or mock

# Provider to use (openai, anthropic, google, mock)
LLM_PROVIDER=mock

# Model name (depends on provider)
# OpenAI: gpt-4, gpt-4-turbo, gpt-3.5-turbo
# Anthropic: claude-3-5-sonnet-20241022, claude-3-opus-20240229, claude-3-haiku-20240307
# Google: gemini-1.5-pro, gemini-1.5-flash
LLM_MODEL=gpt-4

# API Key (required for openai, anthropic, google)
LLM_API_KEY=your-api-key-here

# Base URL (optional, for custom endpoints or proxies)
# OpenAI default: https://api.openai.com/v1
# Anthropic default: https://api.anthropic.com
# Google default: uses default SDK endpoint
LLM_BASE_URL=

# Temperature (0.0 - 2.0, controls randomness)
LLM_TEMPERATURE=0.7

# Max tokens (optional, controls response length)
LLM_MAX_TOKENS=1000

# API Access Tokens
# Add your API tokens here for Envoy to use

# Asana (get from: https://app.asana.com/0/my_apps)
ASANA_ACCESS_TOKEN=your-asana-token-here

# Add other API tokens as needed
# GITHUB_TOKEN=
# SLACK_TOKEN=
